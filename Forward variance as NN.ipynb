{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf0e9f8-85a5-4ff3-b944-a5983e80b7b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T02:27:45.615757Z",
     "iopub.status.busy": "2023-12-30T02:27:45.615470Z",
     "iopub.status.idle": "2023-12-30T02:28:12.914645Z",
     "shell.execute_reply": "2023-12-30T02:28:12.914176Z",
     "shell.execute_reply.started": "2023-12-30T02:27:45.615704Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, IterableDataset\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "from torch.utils.data.sampler import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f82c94f-98c6-43be-8ec9-3b84b1ebd731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:42:15.585077Z",
     "start_time": "2023-08-08T05:42:15.575986Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-30T02:28:12.915890Z",
     "iopub.status.busy": "2023-12-30T02:28:12.915585Z",
     "iopub.status.idle": "2023-12-30T02:28:12.968395Z",
     "shell.execute_reply": "2023-12-30T02:28:12.967528Z",
     "shell.execute_reply.started": "2023-12-30T02:28:12.915868Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = 'cuda' if is_cuda else 'cpu'\n",
    "if not is_cuda:\n",
    "    print(\"Warning: CUDA is not available, use CPU instead\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0fa39e-598b-4660-8155-4a8261fdac67",
   "metadata": {},
   "source": [
    "- Total sample: $1020000$\n",
    "- Train samples: $10^6$\n",
    "- Validate samples: $10^4$\n",
    "- Test samples: $10^4$\n",
    "- batch_size: $2^{12} = 8192$\n",
    "- num_batch: $120$; effective train samples: $120 * 8192 = 983040$\n",
    "- rank_size: $122880 = 15 * 8192$, every time load: $15$ batches \n",
    "- num_rank: $120/15 = 8$, total $8$ times loading \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8746cb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:42:17.427440Z",
     "start_time": "2023-08-08T05:42:17.416395Z"
    },
    "execution": {
     "iopub.execute_input": "2023-12-30T02:28:12.970639Z",
     "iopub.status.busy": "2023-12-30T02:28:12.969921Z",
     "iopub.status.idle": "2023-12-30T02:28:26.799803Z",
     "shell.execute_reply": "2023-12-30T02:28:26.799120Z",
     "shell.execute_reply.started": "2023-12-30T02:28:12.970620Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = 2000\n",
    "T = 1\n",
    "tau = T/M\n",
    "X0 = 0\n",
    "V0 = 0.235**2\n",
    "xi = 0.235**2\n",
    "rho = -0.9\n",
    "nu = 1.9\n",
    "H = 0.07\n",
    "batch_size = 2**13\n",
    "num_batch = 120\n",
    "P_train = num_batch * batch_size# size of train set \n",
    "P_valid = 10000\n",
    "P_test = 10000 # size of test set \n",
    "\n",
    "rank_size = int(15 * batch_size) # sample size for every loading \n",
    "num_rank = int (num_batch/15) # number of loading \n",
    "\n",
    "# epochs = 10\n",
    "# for test set, all moves to cpu\n",
    "x0_t = torch.zeros(P_test, 1, device = device)\n",
    "x0_b = torch.zeros(batch_size, 1, device = device)\n",
    "\n",
    "logmoneyness = np.arange(-0.5, 0.31, 0.01)\n",
    "strikes = np.exp(logmoneyness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be44b8cf-71bc-4ba5-bd47-2b6670099848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T02:28:57.373997Z",
     "iopub.status.busy": "2023-12-30T02:28:57.373755Z",
     "iopub.status.idle": "2023-12-30T02:28:57.382091Z",
     "shell.execute_reply": "2023-12-30T02:28:57.381557Z",
     "shell.execute_reply.started": "2023-12-30T02:28:57.373978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983040"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151051f3-f158-424c-9bd7-b98d10b3bdf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T02:28:26.801651Z",
     "iopub.status.busy": "2023-12-30T02:28:26.801400Z",
     "iopub.status.idle": "2023-12-30T02:28:26.804696Z",
     "shell.execute_reply": "2023-12-30T02:28:26.804160Z",
     "shell.execute_reply.started": "2023-12-30T02:28:26.801628Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "S_path  = \"/lustre1/u/u3553440/const_S/S_total\"\n",
    "V_path = \"/lustre1/u/u3553440/V/V_total\"\n",
    "Z_path = \"/lustre1/u/u3553440/Z/Z_total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "764a0d88-a454-48f8-9af3-a2c3558a23a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T02:28:26.805416Z",
     "iopub.status.busy": "2023-12-30T02:28:26.805217Z",
     "iopub.status.idle": "2023-12-30T02:28:26.825070Z",
     "shell.execute_reply": "2023-12-30T02:28:26.824616Z",
     "shell.execute_reply.started": "2023-12-30T02:28:26.805397Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = [S_path, V_path, Z_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca489af0-b694-4629-969c-a09d11536e57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-30T02:28:26.826029Z",
     "iopub.status.busy": "2023-12-30T02:28:26.825829Z",
     "iopub.status.idle": "2023-12-30T02:28:26.831840Z",
     "shell.execute_reply": "2023-12-30T02:28:26.831374Z",
     "shell.execute_reply.started": "2023-12-30T02:28:26.826010Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "class MyIterable(IterableDataset):\n",
    "    \n",
    "    def __init__(self, file_path: str, start, end):\n",
    "        super(MyIterable, self).__init__()\n",
    "        self.file_path = file_path        \n",
    "        self.start = start\n",
    "        self.end = end\n",
    "   \n",
    "    def __iter__(self):\n",
    "        \n",
    "        # single worker\n",
    "        sample = []\n",
    "        with open(self.file_path, 'r') as f:             \n",
    "            for i, line in enumerate(f):\n",
    "                if i < self.start: continue # 跳出本次循环，直到 i = start, 参与循环\n",
    "                if i >= self.end: # 输出 i = [start, end-1] \n",
    "                    break # 跳出所有循环\n",
    "                \n",
    "                sample.append([float(i) for i in line.split()]) #将读取的字符串转为列表\n",
    "            \n",
    "        return np.array(sample)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        num = 0 \n",
    "        with open(self.file_path, 'r') as f:\n",
    "            for _ in enumerate(f):\n",
    "                num += 1\n",
    "        return num \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35cf68e-4db6-47f5-8c5c-a1e48962226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyDataset(start, rank_size, device, paths):\n",
    "    end = start + rank_size\n",
    "    # load data \n",
    "    ys = MyIterable(paths[0], start, end).__iter__()\n",
    "    mul = MyIterable(paths[1], start, end).__iter__()\n",
    "    z = MyIterable(paths[2], start, end).__iter__()\n",
    "    \n",
    "    # convert numpy array to tensor \n",
    "    ys = torch.from_numpy(ys).to(torch.float32).to(device)\n",
    "    mul = np.c_[np.ones(rank_size), mul[:, :-1]]\n",
    "    mul = torch.from_numpy(mul).to(torch.float32).to(device)\n",
    "    z = torch.from_numpy(z).to(torch.float32).to(device)\n",
    "    \n",
    "    train_rank = TensorDataset(ys, mul, z)\n",
    "    \n",
    "    \n",
    "    return train_rank\n",
    "\n",
    "# train_rank_loader = DataLoader(train_rank, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef2287-9ece-4a7a-bd2b-13b001135231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the available cuda memory\n",
    "def checkmem():\n",
    "    free =  torch.cuda.mem_get_info()[0]//(1024**3)\n",
    "    total = torch.cuda.mem_get_info()[1]//(1024**3)\n",
    "    print(f\"Free memory: {free:>5f}GB/ {total:>5f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711caa01-a561-41a1-88f4-00c4d5aeb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the validate set \n",
    "start_valid = 1000000\n",
    "valid_set = MyDataset(start_valid, P_valid, device, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a0d10-4997-4d61-a400-48514e3f5cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load test set\n",
    "start_test = 1010000\n",
    "test_set = MyDataset(start_test, P_test, device, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62eca7c-7d04-4fd9-a968-9140c638c2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62910d60-77b6-462c-8f3f-70daaeb4d65f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:42:21.491221Z",
     "start_time": "2023-08-08T05:42:19.608124Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# real samples\n",
    "rbergomi_ys = np.load(\"SOE_2000_6_price.npy\") # size (P, M) \n",
    "\n",
    "mul = np.load(\"SOE_2000_6_volatility.npy\") # size (P, M)\n",
    "\n",
    "# volatility at t_0 to t_{M-1}\n",
    "mul = np.c_[np.ones(1000000), mul[:,:-1]]\n",
    "\n",
    "# precomputed Brownian motion paths that drive the stock price\n",
    "Z = np.load(\"SOE_2000_6_Bm.npy\") # size (P, M)\n",
    "\n",
    "\n",
    "# Convert numpy array to tensor\n",
    "# only remain the first P paths \n",
    "rbergomi_ys = torch.from_numpy(rbergomi_ys).to(torch.float32).to(device)[:P, :]\n",
    "mul = torch.from_numpy(mul).to(torch.float32).to(device)[:P, :]\n",
    "Z = torch.from_numpy(Z).to(torch.float32).to(device)[:P, :]\n",
    "\n",
    "# dataset \n",
    "dataset = TensorDataset(rbergomi_ys, mul, Z)\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [P_train, P_test])\n",
    "\n",
    "# train dataloader \n",
    "train_dataloader = DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7271f81",
   "metadata": {},
   "source": [
    "## Stock price \n",
    "$X(t) = logS(t)$\n",
    "\n",
    "$dX(t) = -\\frac{1}{2}V(t)dt + \\sqrt{V(t)}dZ(t)$\n",
    "\n",
    "where $X(0) = logS(0) = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d5afe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:43:53.447357Z",
     "start_time": "2023-08-08T05:43:53.433062Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class my_MLP(torch.nn.Module):\n",
    "    def __init__(self, in_size, mlp_size, num_layers):\n",
    "        # in_size: input size \n",
    "        # mlp_size: size of hidden layers \n",
    "        # num_layers: num of hidden layers \n",
    "        super().__init__()\n",
    "    \n",
    "        model = [torch.nn.Linear(in_size, mlp_size), torch.nn.LeakyReLU(0.1)]\n",
    "        for _ in range(num_layers - 1):\n",
    "            model.append(torch.nn.Linear(mlp_size, mlp_size))\n",
    "            model.append(torch.nn.LeakyReLU(0.1))\n",
    "            \n",
    "        #output size: 1\n",
    "        model.append(torch.nn.Linear(mlp_size, 1))\n",
    "        # model.append(torch.nn.Tanh())\n",
    "    \n",
    "        self._model = torch.nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._model(x) \n",
    "    \n",
    "\n",
    "# numerical SDE solver \n",
    "# specifically applies to rough bergomi model \n",
    "# can only deal with the 1-dim BM case and use forward Euler method \n",
    "class sdeint:\n",
    "    def __init__(self, neural_sde, x0, ts, mul, Z):\n",
    "        \n",
    "        # forward variance curve as neural sde \n",
    "        self.neural_sde = neural_sde\n",
    "        # initial log stock price \n",
    "        self.x0 = x0 #(batch_size, )\n",
    "        self.batch_size = x0.shape[0]        \n",
    "        \n",
    "        # discretized time grid\n",
    "        self.ts = ts #(M, )\n",
    "        self.num_grid = ts.shape[0] # =M\n",
    "        self.tau = ts[1] - ts[0]\n",
    "        \n",
    "        # precomputed paths of volatility and Brownian motion  \n",
    "        self.mul = mul\n",
    "        self.Z = Z        \n",
    "    \n",
    "        \n",
    "    def __call__(self):\n",
    "        # forward Euler \n",
    "        neural_xs = torch.zeros(self.batch_size, self.num_grid + 1, device = device)       \n",
    "        \n",
    "        for i in range(1, self.num_grid+1):\n",
    "            t = ts[i-1]\n",
    "            V = self.neural_sde(t.reshape(-1,1)).squeeze(-1) * self.mul[:, i-1] #(batch_size, )\n",
    "            neural_xs[:, i] = neural_xs[:, i-1] - V * self.tau/2 + torch.sqrt(V) * self.Z[:, i-1]\n",
    "            \n",
    "        return neural_xs[:, 1:] #(batch_size, M)\n",
    "\n",
    "\n",
    "def price(ys, strikes):\n",
    "    sample_size = ys.size(0) \n",
    "    strike_size = strikes.shape[0] # strikes is a 1-d array, has shape (strike_size, )    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_T = ys[:, -1].cpu().numpy() #(P, )\n",
    "        \n",
    "    Y = np.tile(y_T, (strike_size, 1)) #(strike_size, P)\n",
    "    K = np.tile(np.reshape(strikes, (-1, 1)), (1, sample_size)) #(strike_size, P)\n",
    "    Y_K = Y - K\n",
    "    Y_K[Y_K < 0] = 0\n",
    "    price = np.mean(Y_K, -1) # 1-d array, has shape (strike_size, )\n",
    "    return price\n",
    "\n",
    "\n",
    "#plot the marginal distribution at T and the option price \n",
    "def my_plot(neural_ys, real_ys, neural_price, real_price, strikes):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        neural_ys_1 = neural_ys[:, -1].cpu().numpy()            \n",
    "        real_ys_1 = real_ys[:, -1].cpu().numpy()   \n",
    " \n",
    "    plt.figure(figsize = (12, 5))\n",
    "    plt.subplot(1,2,1)     \n",
    "    _, bins, _ = plt.hist(neural_ys_1, bins = 100, alpha = 0.7, color = \"crimson\", density = True)\n",
    "    bin_width = bins[1] - bins[0]\n",
    "    num_bins = int((real_ys_1.max() - real_ys_1.min()) // bin_width)\n",
    "    plt.hist(real_ys_1, bins = 100 , alpha = 0.7, color = \"dodgerblue\", density = True)\n",
    "    plt.legend([\"Neural SDE\", \"Real\"], fontsize = 12)\n",
    "    plt.xlabel(\"Value\", fontweight = \"heavy\")\n",
    "    plt.ylabel(\"Density\", fontweight = \"heavy\")\n",
    "    plt.title(\"Empirical distribution at t = T\", fontsize = 14, fontweight = \"heavy\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1,2,2)    \n",
    "    plt.plot(strikes, neural_price, color = \"crimson\", lw = 2)\n",
    "    plt.plot(strikes, real_price, color = \"dodgerblue\", lw = 2)\n",
    "    plt.legend([\"Neural SDE price\", \"Real price\"], fontsize = 12)\n",
    "    plt.xlabel(\"Strikes\", fontweight = \"heavy\")\n",
    "    plt.ylabel(\"Price\", fontweight = \"heavy\")\n",
    "    plt.title(\"Option price\", fontsize = 14, fontweight = \"heavy\") \n",
    "    plt.grid(True)\n",
    "    plt.show() \n",
    "    \n",
    "\n",
    "# return the Wasserstein_p distance between two empircial ditributions \n",
    "def Wasserstein_p(real_ys, neural_ys, p):\n",
    "    # real_ys, neural_ys have size (batch_size, M)\n",
    "    \n",
    "    real_ys_sorted, _ = torch.sort(real_ys, 0) #改变行，不改变列\n",
    "    neural_ys_sorted, _ = torch.sort(neural_ys, 0)\n",
    "    loss = torch.mean(torch.abs(real_ys_sorted - neural_ys_sorted)**p, 0)**(1/p) #(M, )\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577ccf3-ab38-4ea0-82b9-5bffed35c6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Xavier initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.001)       \n",
    "\n",
    "forward_var.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b4401-3f42-4e74-9153-aca50ad98f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:44:25.926782Z",
     "start_time": "2023-08-08T05:44:23.080768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# neural_ys \n",
    "forward_var = my_MLP(1, 100, 10)\n",
    "# forward_var = torch.load(\"/lustre1/u/u3553440/NN/const_after_2.pth\")\n",
    "forward_var = forward_var.to(device)\n",
    "\n",
    "ts = torch.linspace(tau, T, M, device = device)\n",
    "neural_ys = sdeint(forward_var, x0_t, ts, test_set[:P_test][1], test_set[:P_test][2])()\n",
    "neural_ys = torch.exp(neural_ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af00464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:44:26.464091Z",
     "start_time": "2023-08-08T05:44:26.455555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "neural_ys[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0faf62-001d-4bcb-b97c-ef70a85557fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad69f1d-6fbe-4435-9fb2-71cd60e6e076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(forward_var, \"/lustre1/u/u3553440/NN/const_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c1627-13e9-4908-b8ab-276d65bb2fb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:44:28.810426Z",
     "start_time": "2023-08-08T05:44:28.407121Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#real_price\n",
    "real_price = price(test_set[:P_test][0], strikes)\n",
    "\n",
    "# neural_price \n",
    "neural_price = price(neural_ys, strikes)\n",
    "\n",
    "# plot before training \n",
    "my_plot(neural_ys, test_set[:P_test][0], neural_price, real_price, strikes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168a32c-6ea1-4092-a17c-f719466c00bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Wasserstein_p(test_set[:int(P_test/2)][0], test_set[int(P_test/2):][0], p = 1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ef372-3a57-49e4-9734-781d16b9eca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# forward_var = torch.load(\"ds_1000.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e71526-d2a8-48d8-9c22-a49dfd8efc77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T05:48:58.798439Z",
     "start_time": "2023-08-08T05:48:58.792455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#optimization\n",
    "my_optimizer = torch.optim.Adam(forward_var.parameters(), lr= 1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(my_optimizer, 'min', verbose = True, patience = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1fe39-ee57-414c-92b4-b3c0104d7f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecdbeda-3935-4d6f-a2af-be601fdb6abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkmem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96187dcd-a163-43a9-97ce-ad9a018068f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T07:28:09.454485Z",
     "start_time": "2023-08-08T06:57:40.741940Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "max_error_history = []\n",
    "# Wasserstein-1 distance as loss function\n",
    "epoch = 5\n",
    "random_rank = list(range(num_rank))\n",
    "random.shuffle(random_rank)\n",
    "for i in range(epoch):    \n",
    "    print(f\"Epoch {i+1}\\n-------------------------\")\n",
    "    for rank in random_rank:\n",
    "        start = rank * rank_size\n",
    "        train_rank = MyDataset(start, rank_size, device, paths)\n",
    "        train_rank_loader = DataLoader(train_rank, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "        for batch, train_samples in enumerate(train_rank_loader):         \n",
    "        \n",
    "            real_samples, mul_samples, Z_samples = train_samples # (batch_size, M)\n",
    "        \n",
    "            neural_samples = sdeint(forward_var, x0_b, ts, mul_samples, Z_samples)()\n",
    "            neural_samples = torch.exp(neural_samples) # (batch_size, M)\n",
    "        \n",
    "            # compute Wasserstein-1 distance at all time grids \n",
    "            loss = Wasserstein_p(real_samples, neural_samples, p = 1)[-1]\n",
    "        \n",
    "            # Wasserstein-1 distance at t = T\n",
    "            loss_history.append(loss.item())\n",
    "        \n",
    "            # average Wasserstein distance at all time steps\n",
    "            # ave_loss = torch.mean(loss)            \n",
    "            price_error = np.abs(price(neural_samples, strikes) - price(real_samples, strikes))\n",
    "            max_error_history.append(price_error.max())        \n",
    "\n",
    "            my_optimizer.zero_grad()\n",
    "            # use the Wasserstein distance at T as loss\n",
    "            loss.backward()\n",
    "            my_optimizer.step()        \n",
    "         \n",
    "            current = batch * batch_size \n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{P_train:>5d}]\")\n",
    "        \n",
    "    random.shuffle(random_rank)\n",
    "    \n",
    "    # check the model's performance on validate set after every epoch \n",
    "    \n",
    "    neural_ys = sdeint(forward_var, x0_t, ts, test_set[:P_test][1], test_set[:P_test][2])()\n",
    "    neural_ys = torch.exp(neural_ys)\n",
    "        \n",
    "    valid_loss = Wasserstein_p(test_set[:P_test][0], neural_ys, p = 1)[-1]\n",
    "    scheduler.step(valid_loss)\n",
    "    print(f\"Valid Loss: {valid_loss:>7f}\")\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c8d5f-94b2-48a3-bd7f-a845575403f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(forward_var,'const_1e.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29902af2-95bb-40c8-b448-e42f01929f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b9a6f-eb7e-4603-8a33-c9434bb4bba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T06:53:14.420959Z",
     "start_time": "2023-08-08T06:53:13.925896Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot after training \n",
    "neural_samples = sdeint(forward_var, x0_t, ts, test_set[:P_test][1], test_set[:P_test][2])()\n",
    "neural_samples = torch.exp(neural_samples)\n",
    "\n",
    "neural_price_aftert = price(neural_samples, strikes)\n",
    "\n",
    "my_plot(neural_samples, test_set[:P_test][0], neural_price_aftert, real_price, strikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7bff47-f2e5-4196-b503-b784fc4d716e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T06:53:46.854047Z",
     "start_time": "2023-08-08T06:53:46.741986Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# total_num_batches = int(P_train/batch_size * 10)\n",
    "# my_x = np.linspace(1, total_num_batches, total_num_batches)\n",
    "#only the first 250 batches will be plotted \n",
    "my_x = np.linspace(1, num_batch * 5, num_batch * 5)\n",
    "my_y_1 = np.array(loss_history)\n",
    "my_y_2 = np.array(max_error_history)\n",
    "plt.figure(figsize = (20, 5))\n",
    "plt.plot(my_x, my_y_1, color = \"dodgerblue\", lw = 1)\n",
    "plt.plot(my_x, my_y_2, color = \"crimson\", lw = 1)\n",
    "# plt.legend([\"Wasserstein-1 distance at T\", \"Max option price error\"], fontsize = 12)\n",
    "plt.xlabel(\"Batch number\", fontweight = \"heavy\")\n",
    "plt.yscale('log')\n",
    "plt.title(\"Learning Curve\", fontsize = 14, fontweight = \"heavy\")    \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62b5035-154c-40ed-8cdc-598b44891995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = open('/lustre1/u/u3553440/NN/deep_loss_history_6','w')\n",
    "file.write(str(loss_history))\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a51d1-3f23-4ec5-96ba-078027deb2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = open('/lustre1/u/u3553440/NN/deep_max_error_6','w')\n",
    "file.write(str(max_error_history))\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8207be-1c0d-4f8e-8420-48dd6293c36c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(forward_var, \"/lustre1/u/u3553440/NN/deep_const_after_6.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d67ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_batch_1 = []\n",
    "my_batch_2 = []\n",
    "for batch, train_samples in enumerate(train_dataloader):\n",
    "    ys_samples, _, _ = train_samples \n",
    "    if batch % 2 == 0:\n",
    "        my_batch_1.append(ys_samples)\n",
    "    else:\n",
    "        my_batch_2.append(ys_samples)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901929d-af55-4f61-aacc-d27911e6d6ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_ = []\n",
    "for i in range(8):\n",
    "    loss_.append(Wasserstein_p(my_batch_1[i], my_batch_2[i], p = 1)[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925da588-4ae9-4624-9ac8-b1b4f7789a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "statistics.mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1260c52-bae3-4bcf-b715-28abce79f757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_x = np.linspace(1, 100 * 8, 100 * 8)\n",
    "plot, axes = plt.subplots(figsize = (20, 6))\n",
    "axes.plot(my_x, sgd_loss_5800[:800], \".:\", color = \"crimson\", lw = 1)\n",
    "axes.plot(my_x, sdg_error_5800[:800], \".:\", color = \"dodgerblue\", lw = 1)\n",
    "\n",
    "axes.set_xlabel(\"Batch number\", fontsize=16)\n",
    "# axes.set_ylabel(r'$err$', fontsize=16)\n",
    "# axes.set_xscale('symlog')\n",
    "axes.set_yscale('symlog', linthresh=0.001)\n",
    "axes.legend([\"Wasserstein-1 distance at T\", \"Max option price error\"], fontsize= \"large\")\n",
    "plt.title(\"Learning curve\", fontsize = 14, fontweight = \"heavy\")    \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfa2cb-db05-4903-8cc6-283716902aad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgd_loss_5800 = np.concatenate([np.load(\"loss_2000_sdg.npy\"), np.load(\"loss_2800_sdg.npy\"), np.array(loss_history)])\n",
    "sdg_error_5800 = np.concatenate([np.load(\"error_2000_sdg.npy\"), np.load(\"error_2800_sdg.npy\"), np.array(max_error_history)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21385d-e5c8-4328-88f1-1adf976efa6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"sgd_1oss_5800.npy\", sgd_loss_5800)\n",
    "np.save(\"sgd_error_5800.npy\", sdg_error_5800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32ed60-b746-4966-882a-e2743cdd4f7a",
   "metadata": {},
   "source": [
    "### Learning curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93270c0d-e44e-4a0e-95fe-d02cf05671ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loss = np.load(\"sgd_1oss_5800.npy\")\n",
    "my_error = np.load(\"sgd_error_5800.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826a33a-8a5b-425d-9e81-cda5c4fb02b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_file(file_name, file):\n",
    "    file_path = \"/lustre1/u/u3553440/figs//Learning curve/{name}\".format(name = file_name)\n",
    "    np.savetxt(file_path, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf35bc-98ee-48cd-a331-0bebfb74b00c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_file(\"loss_hist\", my_loss)\n",
    "save_file(\"error_hist\", my_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be720b6a-6c81-4334-bde1-8aedcdde9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd15f2-b277-45e6-9e21-46f1bc7b83e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
